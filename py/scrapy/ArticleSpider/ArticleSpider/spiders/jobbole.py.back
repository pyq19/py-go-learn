# -*- coding: utf-8 -*-
import re
import scrapy


class JobboleSpider(scrapy.Spider):
    name = "jobbole"
    allowed_domains = ["blog.jobbole.com"]
#    start_urls = ['http://blog.jobbole.com/']
    start_urls = ['http://blog.jobbole.com/110287/']

    def parse(self, response):
#        re_selector = response.xpath('/html/body/div[3]/div[3]/div[1]/div[1]/h1')  # 要把第一个3改成1
#        re_selector = response.xpath('//*[@id="post-110287"]/div[1]/h1/text()')
        re_selector = response.xpath('//div[@class="entry-header"]/h1/text()')
#        response.xpath("//p[@class='entry-meta-hide-on-mobile']/text()").extract()[0].strip().replace('·', '').strip() # 2017/02/18
        ct_selector = response.xpath("//p[@class='entry-meta-hide-on-mobile']/text()")
#        response.xpath("//span[contains(@class, 'vote-post-up')]/h10/text()").extract() # ['2']
        title = re_selector.extract()[0]
        create_time = ct_selector.extract()[0].strip().replace('·', '').strip()
        praise_nums = int(response.xpath("//span[contains(@class, 'vote-post-up')]/h10/text()").extract()[0])
#        response.xpath("//span[contains(@class, 'bookmark-btn')]/text()").extract()[0] # ' 22 收藏'
        fav_nums = response.xpath("//span[contains(@class, 'bookmark-btn')]/text()").extract()[0]
        match_re = re.match(".*?(\d+).*", fav_nums)
        if match_re:
            fav_nums = match_re.group(1)

#        response.xpath("//a[@href='#article-comment']/span/text()").extract()[0] # ' 6 评论'
        comment_nums = response.xpath("//a[@href='#article-comment']/span/text()").extract()[0]        
        match_re = re.match(".*?(\d+).*", comment_nums)
        if match_re:
            comment_nums = match_re.group(1)
        content = response.xpath("//div[@class='entry']").extract()[0]

        create_time = response.xpath("//p[@class='entry-meta-hide-on-mobile']/text()").extract()[0].strip().replace('·', '').strip()
        
#        response.xpath("//p[@class='entry-meta-hide-on-mobile']/a/text()").extract() # ['职场', ' 6 评论 ', '面试']
        tag_list = response.xpath("//p[@class='entry-meta-hide-on-mobile']/a/text()").extract()  
        tag_list = [element for element in tag_list if not element.strip().endswith('评论')]
        tags = ','.join(tag_list) # '职场, 6 评论 ,面试'
        print('xpath------>', title, create_time, praise_nums, fav_nums, comment_nums, tags)

        # 通过CSS选择器提取字段
        title = response.css(".entry-header h1::text").extract_first("").strip()
        create_time = response.css("p.entry-meta-hide-on-mobile::text").extract()[0].strip().replace('·', '').strip()
        praise_nums = response.css(".vote-post-up h10::text").extract()[0]
        fav_nums = response.css("span.bookmark-btn::text").extract()[0]
        match_re = re.match(".*?(\d+).*", fav_nums)
        if match_re:
            fav_nums = match_re.group(1)
        comment_nums = response.css("a[href='#article-comment'] span::text").extract()[0]
        match_re = re.match(".*?(\d+).*", comment_nums)
        if match_re:
            comment_nums = match_re.group(1)
        content = response.css("div.entry").extract()[0]
        tag_list = response.css("p.entry-meta-hide-on-mobile a::text").extract()
        tag_list = [element for element in tag_list if not element.strip().endswith('评论')]
        tags = ','.join(tag_list)
        print('css------>', title, create_time, praise_nums, fav_nums, comment_nums, tags)

